{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNUMDCuPShk2WZCdaf4prN6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jmyth742/AircraftTracker/blob/master/LyndseyCleaner.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54iyYEYuPZts",
        "outputId": "d7478eef-13d0-4b58-b699-102f0e7a1b2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lela Sohna\n",
            "1 spaces in Priyanka Shimar\n",
            "1 spaces in Lela Sohna\n",
            "0 spaces in urbabydollxo\n",
            "8 number of tupes\n",
            "Stats:\n",
            "Length original:979\n",
            "Length cleaned:292, remainder 683\n"
          ]
        }
      ],
      "source": [
        "## put link here between quotes of the google sheets.\n",
        "my_sheets = 'https://docs.google.com/spreadsheets/d/1lvAAhyYeQ2cg7es6clQL8LNrRW5fAhRzUgQhd9s1uhw/edit#gid=837286673'\n",
        "## PLEASE PUT THE USERNAME OF THE CREATOR IN HERE\n",
        "username = \"\"\n",
        "\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "import re\n",
        "from datetime import datetime\n",
        "import gspread\n",
        "from google.auth import default\n",
        "import pandas as pd\n",
        "from google.colab import files\n",
        "import numpy as np\n",
        "from gspread_dataframe import get_as_dataframe, set_with_dataframe\n",
        "import sys\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def flatten(l):\n",
        "    return [item for sublist in l for item in sublist]\n",
        "\n",
        "\n",
        "def three_names_regex(links, usernames,):\n",
        "    \n",
        "    parts = usernames.split(' ') \n",
        "    cleaned_list = []\n",
        "    left_over = []\n",
        "    for link in links:\n",
        "        link = \"\".join(str(link))\n",
        "        if re.search(f'(.*){parts[0]}(.*){parts[1]}(.*){parts[1]}(.*)', link): \n",
        "            cleaned_list.append(link)\n",
        "        else:\n",
        "            left_over.append(link)\n",
        "    return cleaned_list,left_over\n",
        "\n",
        "\n",
        "\n",
        "def two_names_regex(links, usernames,):\n",
        "    \n",
        "    parts = usernames.split(' ') \n",
        "    cleaned_list = []\n",
        "    left_over = []\n",
        "    for link in links:\n",
        "        link = \"\".join(str(link))\n",
        "        if re.search(f'(.*){parts[0]}(.*){parts[1]}(.*)', link): \n",
        "            cleaned_list.append(link)\n",
        "        else:\n",
        "            left_over.append(link)\n",
        "\n",
        "    return cleaned_list,left_over\n",
        "\n",
        "\n",
        "def one_names_regex(links, single_name,):\n",
        "    \n",
        "    cleaned_list = []\n",
        "    left_over = []\n",
        "    for link in links:\n",
        "        link = \"\".join(str(link))\n",
        "        if single_name in link:\n",
        "            cleaned_list.append(link)\n",
        "        else:\n",
        "            left_over.append(link)\n",
        "\n",
        "    return cleaned_list,left_over\n",
        "\n",
        "\n",
        "def generate_regex(name,links):\n",
        "    master_list = []\n",
        "    left_over_links = []\n",
        "    \n",
        "    count = 0\n",
        "    numbers = name.split(' ')\n",
        "    count = len(numbers) -1 \n",
        "\n",
        "    if count == 0 :\n",
        "        print(f'{count} spaces in {name}')\n",
        "        master_list,left_over_links = one_names_regex(links,name)\n",
        "        # for i in range(len(master_list)):\n",
        "        #     if \"https://fapello.com/feed/87616/\" in master_list[i]:\n",
        "        #         print(\"gotcha\")\n",
        "    elif count == 1:\n",
        "        print(f'{count} spaces in {name}')\n",
        "        master_list,left_over_links = two_names_regex(links,name)\n",
        "    elif count == 2:\n",
        "        print(f'{count} spaces in {name}')\n",
        "        master_list,left_over_links = three_names_regex(links,name)\n",
        "\n",
        "    return master_list,left_over_links\n",
        "\n",
        "\n",
        "def postProc(creator,my_sheets):\n",
        "\n",
        "  creds, _ = default()\n",
        "  gc = gspread.authorize(creds)\n",
        "\n",
        "\n",
        "  tuple_lists = []\n",
        "  master_list = []\n",
        "  left_overs = []\n",
        "\n",
        "  my_sheets = my_sheets[39:]\n",
        "  idx = my_sheets.find('/')\n",
        "  my_sheets = my_sheets[:idx]\n",
        "  # print(my_sheets)\n",
        "\n",
        "  clients_sheets = gc.open('Ceartas Customers').sheet1\n",
        "  filter_names = ''\n",
        "  removals = ''\n",
        "  print(creator)\n",
        "  clients_df = get_as_dataframe(clients_sheets)\n",
        "  for i in range(len(clients_df['USERNAME'])):\n",
        "    names_ = clients_df['USERNAME'][i]\n",
        "    # print(type(names_),i,clients_df['USERNAME'][i])\n",
        "    names_ = names_.split(',')\n",
        "    if creator in names_[0]:\n",
        "      filter_names = clients_df['FILTER_NAMES'][i]\n",
        "      removals = clients_df['FILTER_REMOVALS'][i] \n",
        "    # else:\n",
        "    #   print(\"no creator found.\")\n",
        "    #   sys.exit(1)\n",
        "  worksheet = gc.open('Ceartas Whitelist').sheet1\n",
        "\n",
        "  sheets = gc.open_by_key(my_sheets)\n",
        "  # print(sheets)\n",
        "  links = sheets.sheet1.get_all_values()\n",
        "\n",
        "  links = flatten(links)\n",
        "\n",
        "  for j in range(len(links)):\n",
        "      links[j] = links[j].lower()\n",
        "\n",
        "  filter_names = filter_names.split(',')  \n",
        "\n",
        "  for n in filter_names:\n",
        "      tuple_lists += generate_regex(n,links)\n",
        "\n",
        "\n",
        "\n",
        "  print(f'{len(tuple_lists)} number of tupes')\n",
        "\n",
        "  for i in range(0,len(tuple_lists),2):\n",
        "      master_list += tuple_lists[i]# 0,2,4\n",
        "      left_overs += tuple_lists[i+1]# 1,3,5\n",
        "  \n",
        "  z = list(set(links) - set(master_list))\n",
        "  remainder = np.array(z, dtype=str)\n",
        "  np.sort(remainder)\n",
        "  rem = np.unique(remainder)    \n",
        "  df_rem = pd.DataFrame(rem)\n",
        "  rem_links = sheets.add_worksheet(title=\"remainder\",rows=len(rem), cols=1)\n",
        "  set_with_dataframe(rem_links, df_rem)\n",
        "\n",
        "\n",
        "  dirty = np.array(master_list, dtype=str)\n",
        "  np.sort(dirty)\n",
        "  data = np.unique(dirty)    \n",
        "  df = pd.DataFrame(data)\n",
        "  cleaner = sheets.add_worksheet(title=\"regex_tests\",rows=len(data), cols=1)\n",
        "  set_with_dataframe(cleaner, df) \n",
        "\n",
        "  print(f'Stats:\\nLength original:{len(links)}\\nLength cleaned:{len(data)}, remainder {len(rem)}')\n",
        "\n",
        "\n",
        "postProc(username,my_sheets)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nOomHuReXMSJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}